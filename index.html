<!DOCTYPE html>
<html lang="en">
<head>
    <title></title>
    <meta charset="utf-8" />
    <link rel="icon" href="favicon.png" type="image/x-icon" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0"> 
    <link href="css/vendor/bootstrap.css" rel="stylesheet" />
    <link href="css/vendor/font-awesome.css" rel="stylesheet" />
    <link href="css/vendor/slick.css" rel="stylesheet" />
    <link href="css/vendor/slick-theme.css" rel="stylesheet" />
    <link href="css/vendor/odometer-theme-default.css" rel="stylesheet" />
    <link href="css/main.css" rel="stylesheet" />
</head>
<body>

    <header>
        <div class="container">
            <div class="logo">
                <a href="index.html"><img src="assets/img/thu2.png" alt="" width="80" height="80"/></a>
            </div>
            <div class="menu">
                <ul>

                </ul>
            </div>
            <div class="mobile-menu"><i class="fa fa-bars"></i></div>
        </div>
    </header>

    <div class="home-slider">
        <div class="home-slider--wrapper">
            <div>
                <div class="home-slider--wrapper__inner" style="background-image: url('assets/img/Tsinghua_dataset.png')">
                    <div class="container">
                        <h3>Mobile Robot Oriented Large-Scale Indoor Dataset for Dynamic Scene Understanding</h3>
                        <h1>THUD Robotic Dataset</h1>
                        <span class="dot-dash">.</span>
                        <h3>Yi-Fan Tang†, Cong Tai†, Fang-Xing Chen†, Wan-Ting Zhang, Tao Zhang, Xue-Ping Liu, Yong-Jin Liu, Long Zeng∗</h3>
                        <h3>Tsinghua university</h3>
                        <p>Most existing robotic datasets capture static scene
                            data and thus are limited in evaluating robots’ dynamic perfor-
                            mance. To address this, we present a mobile robot oriented large-
                            scale indoor dataset, denoted as THUD (Tsinghua University
                            Dynamic) robotic dataset, for training and evaluating their
                            dynamic scene understanding algorithms. Specifically, the THUD
                            dataset construction is first detailed, including organization,
                            acquisition, and annotation methods. It comprises both real-
                            world and synthetic data, collected with a real robot platform
                            and a physical simulation platform, respectively.</p>
                        <div class="slider-buttons">
                            <!-- <a href="assets/THUD_Robotic_Dataset_TOS.pdf" class="button">Dataset Application Form</a> -->
                            <a href="assets/THUD_Robotic_Dataset_TOS.pdf" class="button" id="myButton">Dataset Application Form</a>
                            <a href="#" class="button button-w">PAPER</a>
                            <a href="https://github.com/jackyzengl/THUD_Dataset_Overview" class="button button-w">Github</a>
                        </div>
                    </div>
                </div>
            </div>
        </div>

        <div class="home-slider--anchor">
            <span><i class="fa fa-anchor" aria-hidden="true"></i></span>
        </div>
    </div>

    <div class="wrapper">
        <section class="four-elements">
            <div class="container">
                <div class="row">
                    <div class="col-md-3 col-sm-6 col-xs-12">
                        <div class="four-elements--image"><i class="fa fa-lightbulb-o" aria-hidden="true"></i></div>
                        <h3>large scale & dynamic</h3>
                        <p>Our dataset provides dynamic annotated data for large scale indoor scene which contains amount of dynamic objects that present significant challenges for robot tasks.</p>
                    </div>
                    <div class="col-md-3 col-sm-6 col-xs-12">
                        <div class="four-elements--image"><i class="fa fa-lightbulb-o" aria-hidden="true"></i></div>
                        <h3>scene understanding</h3>
                        <p>Our dataset supports training and testing for various robotic scene understanding tasks (object detection, semantic segmentation, robot relocalization, scene reconstruction, etc.)</p>
                    </div>
                    <div class="col-md-3 col-sm-6 col-xs-12">
                        <div class="four-elements--image"><i class="fa fa-lightbulb-o" aria-hidden="true"></i></div>
                        <h3>selective focus</h3>
                        <p> Our dataset contains both real and synthetic annotated data, the expansion of its size and capabilities has great potential in the future.</p>
                    </div>
                    <div class="col-md-3 col-sm-6 col-xs-12">
                        <div class="four-elements--image"><i class="fa fa-lightbulb-o" aria-hidden="true"></i></div>
                        <h3>Rich labels</h3>
                        <p>Multiple labels such as instance segmentation, semantic segmentation, 3D/2D object detection, Depth, RGB, pose, etc., widely applicable in various fields.</p>
                    </div>
                </div>
            </div>
        </section>

        <!-- <section class="our-history">
            <div class="container">
                <div class="row">
                    <div class="col-md-5 col-sm-12 col-xs-12">
                        <img src="assets/img/Monitor.png" alt="" />
                        <video controls width="506" height="407">
                            <source src="assets/moive/step2-4.mp4" type="video/mp4">
                        </video>
                    </div>
                    <div class="col-md-7 col-sm-12 col-xs-12">
                        <h2>Dataset Video</h2>
                        <p>The video on the right showcases an overview of our dataset, including real data collection hardware, and more.</p>
                        <p>Similarly, we also provide an introduction to the advantages of the dataset, including various statistics of the dataset.</p>
                        <a href="about.html" class="button">Browse Our Work</a>
                    </div>
                </div>
            </div>
        </section> -->

        <section class="our-history">
            <div class="video-container">
                <div class="video-wrapper">
                    <h1 class="video-title">Display Video:</h1>
                    <video controls width="100%" height="auto" class="rounded-video">
                        <source src="assets/moive/dataset_v4.mp4" type="video/mp4">
                    </video>
                </div>
            </div>
        </section>

        <section class="statistics">
            <div class="container">
                <!-- <div class="statistics--item">
                    <div class="statistics--item__image"><i class="fa fa-thumbs-o-up"></i></div>
                    <h3>8</h3>
                    <h5>Real scene frames</h5>
                </div>
                <div class="statistics--item">
                    <div class="statistics--item__image"><i class="fa fa-thumbs-o-up"></i></div>
                    <h3>4</h3>
                    <h5>Synthetic scene frames</h5>
                </div>
                <div class="statistics--item">
                    <div class="statistics--item__image"><i class="fa fa-thumbs-o-up"></i></div>
                    <h3>8888</h3>
                    <h5>3D object detection label</h5>
                </div>
                <div class="statistics--item">
                    <div class="statistics--item__image"><i class="fa fa-thumbs-o-up"></i></div>
                    <h3>8888</h3>
                    <h5>2D object detection label</h5>
                </div>
                <div class="statistics--item">
                    <div class="statistics--item__image"><i class="fa fa-thumbs-o-up"></i></div>
                    <h3>8888</h3>
                    <h5>Semantic segmentation label</h5>
                </div> -->
            </div>
        </section>


        <section class="image-section">
            <div class="image-wrapper">
            <h1 class="pic-title">THUD-Robot Dataset:</h1>
              <img src="assets/img/THUD_head.png" alt="Image 1">
            </div>
            <hr class="divider">
        </section>

        <section class="image-section">
            <div class="image-wrapper">
            <h1 class="pic-title">Mobile robot synthetic data acquisition platform:</h1>
              <img src="assets/img/platform.png" alt="Image 1">
            </div>
            <hr class="divider">
        </section>

        <section class="image-section">
            <div class="image-wrapper">
            <h1 class="pic-title">Statistics of annotations in our dataset:</h1>
              <img src="assets/img/Statistics.png" alt="Image 1">
            </div>
            <hr class="divider">
        </section>

        <section class="image-section-long">
            <div class="image-wrapper">
            <h1 class="pic-title-2">Synthetic Scenes:</h1>
              <img src="assets/img/SyntheticScenes.png" alt="Image 1">
            </div>
            <hr class="divider">
        </section>

        <section class="image-section-long">
            <div class="image-wrapper">
            <h1 class="pic-title-2">Real Scenes:</h1>
              <img src="assets/img/RealScenes.png" alt="Image 1">
            </div>
            <hr class="divider">
        </section>

        <section class="image-section">
            <div class="image-wrapper">
            <h1 class="pic-title">RGB-D Datasets Comparison:</h1>
              <img src="assets/img/Datasets_Comparison.png" alt="Image 1">
            </div>
            <hr class="divider">
        </section>



        <section class="partners">
            <div class="container">
                <h2>Cooperative unit</h2>
                <p>Thank you to the following units for their support and assistance.</p>
                <span class="dot-dash dark">.</span>
                <div class="partners--container">
                    <div class="partners--item">
                        <div class="partners--item__image">
                            <img src="assets/img/thu3.png" alt="">
                        </div>
                    </div>
                    <div class="partners--item">
                        <div class="partners--item__image">
                            <img src="assets/img/shuju&xinxi.png" alt="">
                        </div>
                    </div>
                    <div class="partners--item">
                        <div class="partners--item__image">
                            <img src="assets/img/immv_sigle.png" alt="">
                        </div>
                    </div>
                    <div class="partners--item">
                        <div class="partners--item__image">
                            <img src="assets/img/pudu.png" alt="">
                        </div>
                    </div>
                    <div class="partners--item">
                        <div class="partners--item__image">
                            <img src="assets/img/pudu_tech.png" alt="">
                        </div>
                    </div>
                </div>
            </div>
        </section>

        <section class="get-started">
            <div class="container">
                <h2>If you use the ScanNet data or code please cite:</h2>
                <p>@inproceedings{2024ICRA,<br>
                    title={Mobile Oriented Large-Scale Indoor Dataset for Dynamic Scene Understanding},<br>
                    author={Yi-Fan Tang, Cong Tai, Fang-Xin Chen, Wan-Ting Zhang, Tao Zhang, Yong-Jin Liu, Long Zeng*},<br>
                    booktitle = {Mobile Oriented Large-Scale Indoor Dataset for Dynamic Scene Understanding, submitted to IEEE International Conference Robotic and Automation, 2024.}},<br>
                </p>
                <a href="#" class="button">full papers</a>
            </div>
        </section>
    </div>

    <footer>
        <div class="container">
            <div class="row">
                <div class="col-md-6 col-sm-12">
                    <!-- <ul>
                        <li><a href="#"><i class="fa fa-facebook"></i></a></li>
                        <li><a href="#"><i class="fa fa-twitter"></i></a></li>
                        <li><a href="#"><i class="fa fa-rss"></i></a></li>
                        <li><a href="#"><i class="fa fa-google-plus"></i></a></li>
                        <li><a href="#"><i class="fa fa-linkedin"></i></a></li>
                        <li><a href="#"><i class="fa fa-skype"></i></a></li>
                        <li><a href="#"><i class="fa fa-vimeo"></i></a></li>
                        <li><a href="#"><i class="fa fa-tumblr"></i></a></li>
                    </ul> -->
                </div>
                <div class="col-md-6 col-sm-12">
                    <p><a target="#" href="#" title="Last updated: 2024.5.1">Last updated: 2024.5.1</a></p>
                    <p>Number of downloads:<span id="clickCount">0</span></p>
                </div>
            </div>
        </div>
    </footer>

    <script type="text/javascript">
        window.odometerOptions = {
            format: '(,ddd)',
        };
    </script>
    <script src="js/vendor/jquery-3.1.0.min.js"></script>
    <script src="js/vendor/jquery.easing.min.js"></script>
    <script src="js/vendor/tether.js"></script>
    <script src="js/vendor/bootstrap.js"></script>
    <script src="js/vendor/slick.js"></script>
    <script src="js/vendor/isotope.pkgd.min.js"></script>
    <script src="js/vendor/odometer.min.js"></script>
    <script src="js/main.js"></script>
</body>
</html>
